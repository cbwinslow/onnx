{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd0eb19a231d6cdeddfa7d782706fd68cae3c49b44aaf8515299fdcf94304a50177",
   "display_name": "Python 3.6.12 64-bit ('tf2': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "eb19a231d6cdeddfa7d782706fd68cae3c49b44aaf8515299fdcf94304a50177"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Inference Demo for ImageNet Models (With ONNXRuntime)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Overview\n",
    "\n",
    "This notebook can be used for inference on ONNX models trained on **ImageNet** dataset. The demo shows how to use the trained models to do inference in ONNXRuntime. Please install the prerequisite packages if not already installed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Prerequisites\n",
    "\n",
    "* Protobuf compiler - `sudo apt-get install protobuf-compiler libprotoc-dev` (required for ONNX. This will work for any linux system. For detailed installation guidelines head over to [ONNX documentation](https://github.com/onnx/onnx#installation))\n",
    "* ONNX - `pip install onnx`\n",
    "* ONNXRuntime - `pip install onnxruntime`\n",
    "* matplotlib - `pip install matplotlib`\n",
    "* PIL - `pip install Pillow`\n",
    "* numpy - `pip install numpy`\n",
    "* cv2 - `pip install opencv-python`\n",
    "\n",
    "In order to do inference with a python script: \n",
    "* Generate the script : In Jupyter Notebook browser, go to File -> Download as -> Python (.py)\n",
    "* Run the script: `python imagenet_inference.py`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import dependencies\n",
    "\n",
    "Verify that all dependencies are installed using the cell below. Continue if no errors encountered, warnings can be ignored."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "### Test Images\n",
    "\n",
    "A test image will be downloaded to test out inference. Feel free to provide your own image instead.\n",
    "\n",
    "Use `wget 'https://s3.amazonaws.com/model-server/inputs/kitten.jpg'` to download image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Download label file for ImageNet\n",
    "\n",
    "Download and load synset.txt file containing class labels for ImageNet\n",
    "\n",
    "`wget 'https://s3.amazonaws.com/onnx-model-zoo/synset.txt'`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synset.txt', 'r') as f:\n",
    "    labels = [l.rstrip() for l in f]"
   ]
  },
  {
   "source": [
    "### Import ONNX model\n",
    "\n",
    "Import an onnx model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'resnet50-v1-12.onnx'\n",
    "model = onnx.load(model_path)\n",
    "session = ort.InferenceSession(model.SerializeToString(), None)"
   ]
  },
  {
   "source": [
    "### Read image\n",
    "\n",
    "`get_image(path, show=False)` : Read and show the image taking the `path` as input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path, show=False):\n",
    "    with Image.open(path) as img:\n",
    "        img = np.array(img.convert('RGB'))\n",
    "    if show:\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    return img"
   ]
  },
  {
   "source": [
    "### Preprocess image\n",
    "\n",
    "`preprocess(img)` : Preprocess inference image -> scale to 0~1, resize to 256x256, take center crop of 224x224, normalize image, transpose to NCHW format, cast to float32 and add a dimension to batchify the image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = img / 255.\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    y0 = (h - 224) // 2\n",
    "    x0 = (w - 224) // 2\n",
    "    img = img[y0 : y0+224, x0 : x0+224, :]\n",
    "    img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "    img = np.transpose(img, axes=[2, 0, 1])\n",
    "    img = img.astype(np.float32)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "source": [
    "### Predict\n",
    "\n",
    "`predict(path)` : Takes `path` of the input image and flag to display input image and prints 1 top predictions\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path):\n",
    "    img = get_image(path, show=True)\n",
    "    img = preprocess(img)\n",
    "    ort_inputs = {session.get_inputs()[0].name: img}\n",
    "    preds = session.run(None, ort_inputs)[0]\n",
    "    preds = np.squeeze(preds)\n",
    "    a = np.argsort(preds)[::-1]\n",
    "    print('class=%s ; probability=%f' %(labels[a[0]],preds[a[0]]))"
   ]
  },
  {
   "source": [
    "### Generate predictions\n",
    "\n",
    "The top 1 class along with the probabilities generated for the image is displayed in the output of the cell below\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter path to the inference image below\n",
    "img_path = 'kitten.jpg'\n",
    "predict(img_path)"
   ]
  }
 ]
}