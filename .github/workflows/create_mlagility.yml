# Create ONNX model from mlagility

name: Create ONNX model from mlagility

on:
  schedule:
    - cron:  '00 00 * * MON'
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.8']

    steps:
      - uses: actions/checkout@v3
        name: Checkout repo
      - uses: conda-incubator/setup-miniconda@v2
        with:
          miniconda-version: "latest"
          activate-environment: mla
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies and mlagility
        run: |
          python -m pip install --upgrade pip
          python -m pip install onnx onnxruntime requests py-cpuinfo
          # Print CPU info for debugging ONNX Runtime inference difference
          python -m cpuinfo
          # or python -m pip install mlagility
          python -m pip install transformers
          git clone https://github.com/groq/mlagility.git
          cd mlagility
          pip install -r models/requirements.txt
          pip install -e .

      - name: Run mlagility
        run: |
          ZOO_OPSET_VERSION=17
          benchit mlagility/models/torch_hub/alexnet.py --cache-dir mlagility_models --onnx-opset $ZOO_OPSET_VERSION
          cd mlagility_models/alexnet_torch_hub_2891f54c/onnx/
          git diff --exit-code -- .
          cd ~
          benchit mlagility/models/torchvision/fasterrcnn_resnet50_fpn_v2.py --cache-dir .cache --onnx-opset $ZOO_OPSET_VERSION
          cd mlagility_models/torchvision/fasterrcnn_resnet50_fpn_v2_torchvision_7147702b/onnx/
          git diff --exit-code -- .
